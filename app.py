# app.py (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î - ‡πÄ‡∏û‡∏¥‡πà‡∏° Credit ‡∏ú‡∏π‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á)

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import io
import os
import re
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô (‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á) ---
def clean_compound_name(name):
    """
    ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö: ‡∏•‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏û‡∏π‡∏î, ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á, ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç/‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£, ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå
    """
    if not isinstance(name, str):
        return None
    cleaned_name = name.strip().strip('"')
    
    cleaned_name = re.sub(r'^\d+[\s\-\.]*', '', cleaned_name)
    cleaned_name = re.sub(r'^\([\+\-]\d?\)[\s\-\.]*', '', cleaned_name)
    cleaned_name = re.sub(r'[\s\-\.]*\(\d?\)$', '', cleaned_name)
    cleaned_name = re.sub(r'[\s\-\.]*\[\d?\].*$', '', cleaned_name)
    cleaned_name = re.sub(r'\b\d+\b', '', cleaned_name)
    cleaned_name = re.sub(r'\b[A-Z]\b', '', cleaned_name)

    cleaned_name = cleaned_name.strip()
    
    if not cleaned_name:
        return None
    
    if not re.search(r'[a-zA-Z]{3,}', cleaned_name):
        return None
    
    if cleaned_name.isupper():
        cleaned_name = cleaned_name.title()
    
    return cleaned_name

def parse_report_file(uploaded_file):
    """
    ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå Report ‡∏Ç‡∏≠‡∏á GC-MS/FID
    """
    try:
        sample_name = os.path.splitext(uploaded_file.name)[0]
        file_content = uploaded_file.getvalue().decode("utf-8", errors='ignore')
        lines = [line.strip() for line in file_content.splitlines()]

        peak_list_header_index = -1
        library_search_header_index = -1

        for i, line in enumerate(lines):
            if line.startswith('"Peak","R.T."'):
                peak_list_header_index = i
            elif line.startswith('"PK","RT"'):
                library_search_header_index = i

        if peak_list_header_index == -1:
            return None

        header1 = [name.strip('"') for name in lines[peak_list_header_index].split(',')]
        data_rows1 = []
        
        end_index1 = library_search_header_index if library_search_header_index != -1 else len(lines)
        
        for i in range(peak_list_header_index + 1, end_index1):
            parts = [p.strip() for p in lines[i].split(',')]
            if len(parts) > 1 and parts[0].isdigit():
                data_rows1.append(parts)
        
        if not data_rows1:
            return None

        df_peaks = pd.DataFrame(data_rows1)
        num_cols = min(len(df_peaks.columns), len(header1))
        df_peaks = df_peaks.iloc[:, :num_cols]
        df_peaks.columns = header1[:num_cols]

        df_library = None
        if library_search_header_index != -1:
            header2 = [name.strip('"') for name in lines[library_search_header_index].split(',')]
            data_rows2 = []
            for i in range(library_search_header_index + 1, len(lines)):
                parts = [p.strip() for p in lines[i].split(',')]
                if len(parts) > 1 and parts[0].isdigit():
                    data_rows2.append(parts)
            
            if data_rows2:
                df_library = pd.DataFrame(data_rows2)
                num_cols_lib = min(len(df_library.columns), len(header2))
                df_library = df_library.iloc[:, :num_cols_lib]
                df_library.columns = header2[:num_cols_lib]

        cols_to_convert = ["Peak", "R.T.", "Height", "Area", "Pct Max", "Pct Total"]
        for col in cols_to_convert:
            if col in df_peaks.columns:
                df_peaks[col] = pd.to_numeric(df_peaks[col], errors='coerce')
        df_peaks.dropna(subset=['Peak', 'R.T.'], inplace=True)

        if df_library is not None and 'PK' in df_library.columns:
            df_library['PK'] = pd.to_numeric(df_library['PK'], errors='coerce')
            df_merged = pd.merge(df_peaks, df_library.rename(columns={'PK': 'Peak'}), on='Peak', how='left')
            df_merged.loc[df_merged['Library/ID'].isna(), 'Library/ID'] = 'Unknown'
        else:
            df_merged = df_peaks.copy()
            df_merged['Library/ID'] = 'Unknown'
        
        df_merged['Sample'] = sample_name
        return df_merged
    except Exception:
        return None

def to_excel(df):
    """
    ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö BytesIO
    """
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Data') 
    processed_data = output.getvalue()
    return processed_data

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á UI ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ ---
st.set_page_config(layout="wide")
st.title("Multi-Sample GC-MS Data Comparator")

# === ‡∏à‡∏∏‡∏î‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏° Credit ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà) ===
st.markdown('<p style="color:green; font-weight:bold;">Created by Aniwat Kaewkrod</p>', unsafe_allow_html=True)
# ===============================================

st.write("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Report ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 20 ‡πÑ‡∏ü‡∏•‡πå) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

# ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Session State ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á‡πÅ‡∏≠‡∏õ
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'uploaded_files_list' not in st.session_state:
    st.session_state.uploaded_files_list = []

st.sidebar.header("File Upload")
uploaded_files = st.sidebar.file_uploader(
    "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Report ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì",
    type=None,
    accept_multiple_files=True,
    key="file_uploader"
)

st.sidebar.markdown("---")
col1, col2 = st.sidebar.columns(2)
analyze_button = col1.button("üöÄ Analyze", use_container_width=True, type="primary")
clear_button = col2.button("üóëÔ∏è Clear Data", use_container_width=True)

if clear_button:
    st.session_state.analysis_complete = False
    st.session_state.uploaded_files_list = []
    st.rerun()

if analyze_button and uploaded_files:
    if len(uploaded_files) > 20:
        st.error("‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢, ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡∏∞ 20 ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
    else:
        st.session_state.uploaded_files_list = uploaded_files
        st.session_state.analysis_complete = True
elif analyze_button and not uploaded_files:
    st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏î Analyze")

# --- ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏´‡∏•‡∏±‡∏Å ---
if not st.session_state.analysis_complete:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° 'Analyze' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
    if uploaded_files:
        st.write("‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:")
        for f in uploaded_files:
            st.write(f"- {f.name}")

if st.session_state.analysis_complete and st.session_state.uploaded_files_list:
    
    with st.spinner("Processing data... Please wait."):
        all_data_list = [parse_report_file(f) for f in st.session_state.uploaded_files_list]
        valid_data_list = [df for df in all_data_list if df is not None]

    if not valid_data_list:
        st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏î‡πÜ ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå")
        st.session_state.analysis_complete = False
        st.stop()

    combined_df = pd.concat(valid_data_list, ignore_index=True)
    
    combined_df['Compound'] = combined_df['Library/ID'].apply(clean_compound_name)
    base_analysis_df = combined_df.dropna(subset=['Compound'])
    base_analysis_df = base_analysis_df[base_analysis_df['Compound'] != 'Unknown']

    tab_heatmap, tab_pca, tab_overlay, tab_data = st.tabs([
        "üî• Comparative Heatmap", 
        "üß¨ PCA Clustering", 
        "üìä Overlaid Chromatograms", 
        "üìÑ Combined Data"
    ])

    with tab_heatmap:
        st.header("‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (Heatmap)")
        st.subheader("Display Options")
        
        opt_col1, opt_col2, opt_col3, opt_col4 = st.columns(4)
        with opt_col1:
            value_option = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á:", ("Area", "Height"), key="heatmap_value")
        with opt_col2:
            colorscale_option = st.selectbox(
                "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡∏∏‡∏î‡πÇ‡∏ó‡∏ô‡∏™‡∏µ:",
                ("Plasma", "Viridis", "Cividis", "Blues", "Reds", "Greens", "YlGnBu", "YlOrRd", "Inferno", "Magma"),
                index=0
            )
        with opt_col3:
            filter_contaminants = st.checkbox("‡∏Å‡∏£‡∏≠‡∏á‡∏™‡∏≤‡∏£‡∏õ‡∏ô‡πÄ‡∏õ‡∏∑‡πâ‡∏≠‡∏ô (Siloxanes)", value=True, key="filter_check")
        with opt_col4:
            use_log_scale = st.checkbox("‡πÉ‡∏ä‡πâ‡∏™‡πÄ‡∏Å‡∏•‡∏™‡∏µ‡πÅ‡∏ö‡∏ö Log", value=False, key="log_scale_check")

        st.markdown("---")
        st.subheader("Filter & Sort Compounds")
        search_term = st.text_input("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö (Compound Search):", "").strip().lower()
        sort_option = st.selectbox(
            "‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö (Compound Sort):",
            ("Alphabetical (A-Z)", "Total Abundance (Highest First)", "Variance (Highest First)"),
            key="compound_sort_option"
        )

        CONTAMINANT_KEYWORDS = [
            'cyclosiloxane', 'cyclotrisiloxane', 'cyclopentasiloxane', 
            'cyclotetrasiloxane', 'cyclohexasiloxane', 'cyclododecasiloxane'
        ]
        contaminant_pattern = '|'.join(CONTAMINANT_KEYWORDS)
        
        heatmap_df = base_analysis_df.copy()
        if filter_contaminants:
            heatmap_df = heatmap_df[~heatmap_df['Compound'].str.contains(contaminant_pattern, case=False, regex=True, flags=re.IGNORECASE)]

        if search_term:
            heatmap_df = heatmap_df[heatmap_df['Compound'].str.lower().str.contains(search_term, na=False)]

        if not heatmap_df.empty:
            try:
                heatmap_pivot = heatmap_df.pivot_table(
                    index='Compound', columns='Sample', values=value_option,
                    aggfunc='sum'
                ).fillna(0)
                
                heatmap_pivot = heatmap_pivot[heatmap_pivot.sum(axis=1) > 0]
                
                if not heatmap_pivot.empty:
                    if sort_option == "Total Abundance (Highest First)":
                        heatmap_pivot['__sort_col__'] = heatmap_pivot.sum(axis=1)
                        heatmap_pivot = heatmap_pivot.sort_values(by='__sort_col__', ascending=False).drop(columns='__sort_col__')
                    elif sort_option == "Variance (Highest First)":
                        heatmap_pivot['__sort_col__'] = heatmap_pivot.var(axis=1)
                        heatmap_pivot = heatmap_pivot.sort_values(by='__sort_col__', ascending=False).drop(columns='__sort_col__')
                    else:
                        heatmap_pivot = heatmap_pivot.sort_index(ascending=True)

                    plot_data = heatmap_pivot.copy()
                    color_axis_label = f"{value_option}"
                    
                    if use_log_scale:
                        plot_data = np.log1p(plot_data)
                        color_axis_label = f"Log({value_option})"

                    num_compounds = len(plot_data.index)
                    graph_height = max(500, num_compounds * 22)

                    fig_heatmap = px.imshow(
                        plot_data,
                        labels=dict(x="Sample (‡πÑ‡∏ü‡∏•‡πå)", y="Compound (‡∏™‡∏≤‡∏£)", color=color_axis_label),
                        aspect="auto",
                        color_continuous_scale=colorscale_option,
                        height=graph_height
                    )
                    fig_heatmap.update_layout(
                        xaxis_side="top",
                        yaxis=dict(
                            tickmode='linear', 
                            automargin=True,
                            title_text="Compound (‡∏™‡∏≤‡∏£)",
                            dtick=1
                        ),
                        xaxis=dict(
                            title_text="Sample (‡πÑ‡∏ü‡∏•‡πå)"
                        ),
                        coloraxis_colorbar=dict(
                            title=color_axis_label
                        )
                    )
                    st.plotly_chart(fig_heatmap, use_container_width=True)
                    st.caption("""
                    **Heatmap:** ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏£‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏ô‡∏¥‡∏î (‡πÅ‡∏Å‡∏ô Y) ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡πÅ‡∏Å‡∏ô X)
                    - **‡∏™‡∏µ‡πÄ‡∏Ç‡πâ‡∏°:** ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£ **‡∏ô‡πâ‡∏≠‡∏¢**
                    - **‡∏™‡∏µ‡∏≠‡πà‡∏≠‡∏ô/‡∏™‡∏ß‡πà‡∏≤‡∏á:** ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£ **‡∏°‡∏≤‡∏Å**
                    - **0, 50M, 100M, 500M:** ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£ (M = ‡∏•‡πâ‡∏≤‡∏ô) ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏µ
                    """)

                    st.markdown("---")
                    st.subheader("Export Options")
                    
                    export_col1, export_col2 = st.columns(2)

                    with export_col1:
                        img_bytes = fig_heatmap.to_image(format="jpeg", width=1200, height=graph_height, scale=2)
                        st.download_button(
                            label="üì• Download Heatmap as JPG",
                            data=img_bytes,
                            file_name="heatmap_comparison.jpg",
                            mime="image/jpeg"
                        )
                    
                    with export_col2:
                        excel_data = to_excel(heatmap_pivot)
                        st.download_button(
                            label="üì• Download Heatmap Data as XLSX",
                            data=excel_data,
                            file_name="heatmap_data.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

                else:
                    st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á")
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap ‡∏´‡∏£‡∏∑‡∏≠ Export: {e}")
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏°‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap")

    with tab_pca:
        st.header("‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (PCA Clustering)")
        st.info("‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô")

        pca_col1, pca_col2 = st.columns(2)
        pca_value_option = pca_col1.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:", ("Area", "Height"), key="pca_value")
        use_groups = pca_col2.toggle("‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏™‡πà‡∏™‡∏µ", value=False)
        
        group_map = {}
        if use_groups:
            st.write("‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:")
            all_samples = list(base_analysis_df['Sample'].unique())
            num_groups = st.number_input("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°", min_value=2, max_value=10, value=2, step=1, key="num_groups_pca")
            group_cols = st.columns(num_groups)
            
            selected_samples_in_groups = set()
            for i in range(num_groups):
                with group_cols[i]:
                    group_name = st.text_input(f"‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà {i+1}", value=f"Group {i+1}", key=f"gname_pca_{i}")
                    
                    available_samples = [s for s in all_samples if s not in selected_samples_in_groups]
                    members = st.multiselect(
                        f"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏° {group_name}", 
                        options=available_samples, 
                        key=f"gmembers_pca_{i}"
                    )
                    for member in members:
                        group_map[member] = group_name
                        selected_samples_in_groups.add(member)

        if len(base_analysis_df['Sample'].unique()) < 2:
            st.warning("‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå PCA")
        else:
            try:
                pivot_df = base_analysis_df.pivot_table(index='Compound', columns='Sample', values=pca_value_option, aggfunc='sum').fillna(0)
                
                data_for_pca = pivot_df.T
                
                scaler = StandardScaler()
                scaled_data = scaler.fit_transform(data_for_pca)
                
                pca = PCA(n_components=2)
                principal_components = pca.fit_transform(scaled_data)
                
                pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'], index=data_for_pca.index)
                
                if use_groups and group_map:
                    pca_df['Group'] = pca_df.index.map(group_map).fillna('Ungrouped')
                else:
                    pca_df['Group'] = 'Sample'
                
                explained_variance = pca.explained_variance_ratio_

                st.subheader("PCA Scatter Plot")
                fig_pca = px.scatter(
                    pca_df,
                    x='PC1',
                    y='PC2',
                    color='Group',
                    text=pca_df.index,
                    labels={
                        'PC1': f'PC1 ({explained_variance[0]*100:.2f}%)',
                        'PC2': f'PC2 ({explained_variance[1]*100:.2f}%)'
                    },
                    title="2D PCA of Samples"
                )
                fig_pca.update_traces(textposition='top center')
                
                fig_pca.update_layout(
                    legend_title_text='Groups',
                    xaxis=dict(zeroline=True, zerolinewidth=1, zerolinecolor='LightGrey'),
                    yaxis=dict(
                        zeroline=True, 
                        zerolinewidth=1, 
                        zerolinecolor='LightGrey',
                        scaleanchor="x",
                        scaleratio=1,
                    ),
                )
                
                st.plotly_chart(fig_pca, use_container_width=True)
                st.caption(f"""
                **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ PCA Plot:**
                - ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏£‡∏≤‡∏ü‡∏Ñ‡∏∑‡∏≠ **‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1 ‡πÑ‡∏ü‡∏•‡πå**
                - **‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô** ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡∏ó‡∏µ‡πà **‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô**
                - **‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô** ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ **‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô**
                - **PC1 (Principal Component 1) ‡πÅ‡∏•‡∏∞ PC2 (Principal Component 2)** ‡∏Ñ‡∏∑‡∏≠‡πÅ‡∏Å‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
                - **‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡πÉ‡∏ô‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö:** ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡πÅ‡∏Å‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏î‡πâ‡∏Å‡∏µ‡πà‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå (‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)
                """)

            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì PCA: {e}")

    with tab_overlay:
        st.header("‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏Ñ‡∏£‡∏°‡∏≤‡πÇ‡∏ó‡πÅ‡∏Å‡∏£‡∏°")
        y_overlay_option = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡∏ô Y:", ("Height", "Area"), key="overlay_y")
        fig_overlay = go.Figure()
        samples = combined_df['Sample'].unique()
        colors = px.colors.qualitative.Plotly
        
        for i, sample in enumerate(samples):
            sample_df = combined_df[combined_df['Sample'] == sample]
            fig_overlay.add_trace(go.Scatter(
                x=sample_df['R.T.'], 
                y=sample_df[y_overlay_option],
                mode='lines', 
                name=sample,
                line=dict(color=colors[i % len(colors)])
            ))
        
        fig_overlay.update_layout(
            xaxis_title="Retention Time", 
            yaxis_title=y_overlay_option,
            plot_bgcolor='white',
            xaxis=dict(showline=True, linewidth=2, linecolor='black', showgrid=True, gridwidth=1, gridcolor='lightgrey'),
            yaxis=dict(showline=True, linewidth=2, linecolor='black', showgrid=True, gridwidth=1, gridcolor='lightgrey'),
            legend_title_text='Samples'
        )
        st.plotly_chart(fig_overlay, use_container_width=True)
        st.caption("""
        **Chromatogram Overlay:** ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÇ‡∏Ñ‡∏£‡∏°‡∏≤‡πÇ‡∏ó‡πÅ‡∏Å‡∏£‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ã‡πâ‡∏≠‡∏ô‡∏ó‡∏±‡∏ö‡∏Å‡∏±‡∏ô
        - **‡πÅ‡∏Å‡∏ô X (Retention Time):** ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        - **‡πÅ‡∏Å‡∏ô Y (Height/Area):** ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ
        - **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:** ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏Ñ‡∏£‡∏°‡∏≤‡πÇ‡∏ó‡πÅ‡∏Å‡∏£‡∏°‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
        """)

    with tab_data:
        st.header("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô")
        st.dataframe(combined_df)
        
        st.markdown("---")
        excel_all_data = to_excel(combined_df)
        st.download_button(
            label="üì• Download All Combined Data as XLSX",
            data=excel_all_data,
            file_name="all_combined_data.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
