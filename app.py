# ==============================================================================
# GC-MS Data Comparator & Flavor Explorer
# Complete Version with Integrated Flavor Database (No Word Cloud)
# Created by Aniwat Kaewkrod
# Bug Fixes Applied by Manus
# ==============================================================================

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import io
import os
import re
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# ==============================================================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô
# ==============================================================================

@st.cache_data
def get_flavor_database():
    """
    ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå
    """
    try:
        all_dfs = []
        file_stats = []
        
        flavor_files = [
            'flavordb_descriptive.csv',
            'flavornet_descriptive.csv',
            'flavor_descriptive_master.csv'
        ]
        
        for file_path in flavor_files:
            if os.path.exists(file_path):
                try:
                    df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip')
                    
                    df.columns = [str(col).strip().lower() for col in df.columns]
                    
                    possible_name_cols = ['compound_name', 'compound']
                    possible_flavor_cols = ['flavor_description', 'odor_description', 'flavor', 'descriptors']
                    possible_source_cols = ['source']

                    name_col = next((col for col in possible_name_cols if col in df.columns), None)
                    flavor_col = next((col for col in possible_flavor_cols if col in df.columns), None)
                    source_col = next((col for col in possible_source_cols if col in df.columns), None)

                    temp_df = pd.DataFrame()

                    if name_col and flavor_col:
                        if source_col:
                            temp_df = df[[name_col, flavor_col, source_col]]
                            temp_df.columns = ['Compound', 'Flavor_Descriptor', 'Source']
                        else:
                            temp_df = df[[name_col, flavor_col]]
                            temp_df.columns = ['Compound', 'Flavor_Descriptor']
                            temp_df['Source'] = os.path.splitext(os.path.basename(file_path))[0]
                    
                    if temp_df.empty:
                        st.warning(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå {file_path} ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV)")
                        continue

                    temp_df.dropna(subset=['Compound', 'Flavor_Descriptor'], inplace=True)
                    temp_df['Compound'] = temp_df['Compound'].astype(str).str.strip()
                    temp_df['Flavor_Descriptor'] = temp_df['Flavor_Descriptor'].astype(str).str.strip()
                    
                    temp_df = temp_df[temp_df['Compound'].str.len() > 2]
                    temp_df = temp_df[temp_df['Flavor_Descriptor'].str.len() > 2]
                    
                    file_stats.append({'file': file_path, 'count': len(temp_df)})
                    all_dfs.append(temp_df)
                    
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {file_path}: {e}")
                    continue
        
        if not all_dfs:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô - ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå Flavor Profile ‡πÅ‡∏•‡∏∞ Flavor Explorer ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
            return pd.DataFrame(columns=['Compound', 'Flavor_Descriptor', 'Source'])
        
        combined_df = pd.concat(all_dfs, ignore_index=True)
        combined_df['Compound'] = combined_df['Compound'].str.title()
        combined_df = combined_df.drop_duplicates(subset=['Compound'], keep='first')
        
        st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(combined_df):,} ‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö")
        
        with st.expander("üìä ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"):
            for stat in file_stats:
                st.write(f"- **{stat['file']}**: {stat['count']:,} ‡∏™‡∏≤‡∏£")
            st.write(f"- **‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏´‡∏•‡∏±‡∏á‡∏•‡∏ö‡∏ã‡πâ‡∏≥)**: {len(combined_df):,} ‡∏™‡∏≤‡∏£")
        
        return combined_df
        
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô: {e}")
        return pd.DataFrame(columns=['Compound', 'Flavor_Descriptor', 'Source'])

# ==============================================================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GC-MS
# ==============================================================================

def clean_compound_name(name):
    if not isinstance(name, str):
        return 'Unknown'
    cleaned = name.strip().strip('"').strip("'")
    cleaned = re.sub(r'^\d+[\s\-\.]+', '', cleaned)
    cleaned = re.sub(r'^\([+\-RSEZ]+\)[\s\-\.]*', '', cleaned)
    cleaned = re.sub(r'^\(\d*[RSEZ][\d,RSEZ]*\)[\s\-\.]*', '', cleaned)
    cleaned = re.sub(r'\s*\(\d+\)\s*$', '', cleaned)
    cleaned = re.sub(r'\s+', ' ', cleaned)
    if cleaned.isupper() and len(cleaned) > 3:
        cleaned = cleaned.title()
    cleaned = cleaned.strip()
    if not cleaned or len(cleaned) < 3:
        return 'Unknown'
    return cleaned

def parse_report_file(uploaded_file):
    try:
        sample_name = uploaded_file.name
        file_content = uploaded_file.getvalue().decode("utf-8", errors='ignore')
        lines = [line.strip() for line in file_content.splitlines()]

        peak_list_header_idx = -1
        library_search_header_idx = -1

        for i, line in enumerate(lines):
            if line.startswith('"Peak","R.T."'):
                peak_list_header_idx = i
            elif line.startswith('"PK","RT"'):
                library_search_header_idx = i

        if peak_list_header_idx == -1:
            return None

        header_peaks = [col.strip('"') for col in lines[peak_list_header_idx].split(',')]
        data_peaks = []
        end_idx = library_search_header_idx if library_search_header_idx != -1 else len(lines)
        for i in range(peak_list_header_idx + 1, end_idx):
            if lines[i]:
                parts = lines[i].split(',')
                if parts and parts[0].strip().replace('"', '').isdigit():
                    data_peaks.append(parts)
        
        if not data_peaks:
            return None

        df_peaks = pd.DataFrame(data_peaks)
        num_cols = min(len(df_peaks.columns), len(header_peaks))
        df_peaks = df_peaks.iloc[:, :num_cols]
        df_peaks.columns = header_peaks[:num_cols]

        df_library = None
        if library_search_header_idx != -1:
            header_lib = [col.strip('"') for col in lines[library_search_header_idx].split(',')]
            data_lib = []
            for i in range(library_search_header_idx + 1, len(lines)):
                if lines[i]:
                    parts = lines[i].split(',')
                    if parts and parts[0].strip().replace('"', '').isdigit():
                        data_lib.append(parts)
            if data_lib:
                df_library = pd.DataFrame(data_lib)
                num_cols_lib = min(len(df_library.columns), len(header_lib))
                df_library = df_library.iloc[:, :num_cols_lib]
                df_library.columns = header_lib[:num_cols_lib]

        for col in ["Peak", "R.T.", "Height", "Area"]:
            if col in df_peaks.columns:
                df_peaks[col] = pd.to_numeric(df_peaks[col].astype(str).str.replace('"', ''), errors='coerce')
        df_peaks.dropna(subset=['Peak', 'R.T.'], inplace=True)

        if df_library is not None and 'PK' in df_library.columns:
            df_library['PK'] = pd.to_numeric(df_library['PK'].astype(str).str.replace('"', ''), errors='coerce')
            df_merged = pd.merge(df_peaks, df_library.rename(columns={'PK': 'Peak'}), on='Peak', how='left')
        else:
            df_merged = df_peaks.copy()

        required_cols = ['Library/ID', 'CAS#', 'SI', 'Qual']
        for col in required_cols:
            if col not in df_merged.columns:
                df_merged[col] = 'Unknown'
        df_merged['Library/ID'] = df_merged['Library/ID'].fillna('Unknown')
        df_merged['Sample'] = sample_name
        return df_merged
        
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name}: {str(e)}")
        return None

def to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Data')
    return output.getvalue()

# ==============================================================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞ UI
# ==============================================================================

st.set_page_config(layout="wide", page_title="GC-MS Data Comparator", page_icon="üß™")
st.title("üß™ Multi-Sample GC-MS Data Comparator & Flavor Explorer")
st.markdown('<p style="color:green; font-weight:bold; font-size:16px;">Created by Aniwat Kaewkrod</p>', unsafe_allow_html=True)
st.write("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Report ‡∏à‡∏≤‡∏Å GC-MS (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 20 ‡πÑ‡∏ü‡∏•‡πå) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'uploaded_files_list' not in st.session_state:
    st.session_state.uploaded_files_list = []

# ==============================================================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: Sidebar - File Upload & Control
# ==============================================================================

st.sidebar.header("üìÅ File Upload & Control")

# === FIX: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå ===
st.sidebar.markdown("**1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Report (.CSV ‡∏´‡∏£‡∏∑‡∏≠ .TXT)**")
st.sidebar.info(
    """
    ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå Report ‡∏ó‡∏µ‡πà Export ‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á GC-MS 
    ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Text File) ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:
    - **Peak List** (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ)
    - **Library Search** (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    """
)
uploaded_files = st.sidebar.file_uploader(
    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Report ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì",
    type=['csv', 'txt'],
    accept_multiple_files=True,
    key="file_uploader",
    label_visibility="collapsed" # ‡∏ã‡πà‡∏≠‡∏ô Label ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÅ‡∏•‡πâ‡∏ß
)
# === END FIX ===

st.sidebar.markdown("---")
st.sidebar.markdown("**2. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå**")
col1, col2 = st.sidebar.columns(2)

analyze_button = col1.button("üöÄ Analyze", use_container_width=True, type="primary")
clear_button = col2.button("üóëÔ∏è Clear Data", use_container_width=True)

if clear_button:
    st.session_state.analysis_complete = False
    st.session_state.uploaded_files_list = []
    st.rerun()

if analyze_button and uploaded_files:
    if len(uploaded_files) > 20:
        st.error("‚ùå ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡∏∞ 20 ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
    else:
        st.session_state.uploaded_files_list = uploaded_files
        st.session_state.analysis_complete = True
        st.rerun()
elif analyze_button and not uploaded_files:
    st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏î Analyze")

# ==============================================================================
# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: Main Display Area
# ==============================================================================

if not st.session_state.analysis_complete:
    st.info("üìå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° 'Analyze' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
    if uploaded_files:
        st.write("**‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:**")
        for idx, f in enumerate(uploaded_files, 1):
            st.write(f"{idx}. ‚úì {f.name}")

if st.session_state.analysis_complete and st.session_state.uploaded_files_list:
    with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•... ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà"):
        all_data_list = [parse_report_file(f) for f in st.session_state.uploaded_files_list]
        valid_data_list = [df for df in all_data_list if df is not None]

    if not valid_data_list:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏î‡πÜ ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå")
        st.session_state.analysis_complete = False
        st.stop()

    combined_df = pd.concat(valid_data_list, ignore_index=True)
    combined_df['Compound'] = combined_df['Library/ID'].apply(clean_compound_name)
    base_analysis_df = combined_df[combined_df['Compound'] != 'Unknown'].copy()

    num_samples = len(valid_data_list)
    num_compounds = len(base_analysis_df['Compound'].unique())
    num_peaks = len(base_analysis_df)
    
    col_stat1, col_stat2, col_stat3 = st.columns(3)
    col_stat1.metric("üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏ü‡∏•‡πå", f"{num_samples} ‡πÑ‡∏ü‡∏•‡πå")
    col_stat2.metric("üß™ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏£", f"{num_compounds} ‡∏™‡∏≤‡∏£")
    col_stat3.metric("üìà ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Peaks", f"{num_peaks} peaks")
    st.success("‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

    tabs = st.tabs(["üî• Comparative Heatmap", "üß¨ PCA Clustering", "üëÉ Flavor Profile", "üîç Flavor Explorer", "üìä Overlaid Chromatograms", "üìÑ Combined Data"])

    with tabs[0]:
        st.header("üî• ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
        st.subheader("‚öôÔ∏è Display Options")
        opt_col1, opt_col2, opt_col3, opt_col4 = st.columns(4)
        value_option = opt_col1.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á:", ("Area", "Height"), key="heatmap_value")
        colorscale_option = opt_col2.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡∏∏‡∏î‡πÇ‡∏ó‡∏ô‡∏™‡∏µ:", ("Plasma", "Viridis", "Cividis", "Blues", "Reds", "Greens", "YlGnBu", "YlOrRd", "Inferno", "Magma", "Turbo"), index=0)
        filter_contaminants = opt_col3.checkbox("‡∏Å‡∏£‡∏≠‡∏á‡∏™‡∏≤‡∏£ Siloxanes", value=True, key="filter_check")
        use_log_scale = opt_col4.checkbox("‡πÉ‡∏ä‡πâ‡∏™‡πÄ‡∏Å‡∏•‡∏™‡∏µ‡πÅ‡∏ö‡∏ö Log", value=False, key="log_scale_check")
        st.markdown("---")
        st.subheader("üîé Filter & Sort")
        filter_col1, filter_col2 = st.columns(2)
        search_term = filter_col1.text_input("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö:", "", placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤...").strip().lower()
        sort_option = filter_col2.selectbox("‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö:", ("Alphabetical (A-Z)", "Total Abundance (Highest First)", "Variance (Highest First)"), key="compound_sort")

        CONTAMINANT_KEYWORDS = ['siloxane', 'cyclotrisiloxane', 'cyclopentasiloxane', 'cyclotetrasiloxane', 'cyclohexasiloxane', 'cyclododecasiloxane']
        contaminant_pattern = '|'.join(CONTAMINANT_KEYWORDS)
        heatmap_df = base_analysis_df.copy()
        if filter_contaminants:
            heatmap_df = heatmap_df[~heatmap_df['Compound'].str.contains(contaminant_pattern, case=False, na=False)]
        if search_term:
            heatmap_df = heatmap_df[heatmap_df['Compound'].str.lower().str.contains(search_term, na=False)]

        if not heatmap_df.empty:
            try:
                heatmap_pivot = heatmap_df.pivot_table(index='Compound', columns='Sample', values=value_option, aggfunc='sum').fillna(0)
                heatmap_pivot = heatmap_pivot[heatmap_pivot.sum(axis=1) > 0]
                if not heatmap_pivot.empty:
                    if sort_option == "Total Abundance (Highest First)":
                        heatmap_pivot = heatmap_pivot.loc[heatmap_pivot.sum(axis=1).sort_values(ascending=False).index]
                    elif sort_option == "Variance (Highest First)":
                        heatmap_pivot = heatmap_pivot.loc[heatmap_pivot.var(axis=1).sort_values(ascending=False).index]
                    else:
                        heatmap_pivot = heatmap_pivot.sort_index(ascending=True)

                    plot_data = np.log1p(heatmap_pivot) if use_log_scale else heatmap_pivot
                    color_label = f"Log({value_option})" if use_log_scale else value_option
                    graph_height = max(600, min(len(plot_data.index) * 25, 3000))

                    fig_heatmap = px.imshow(plot_data, labels=dict(x="Sample (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)", y="Compound (‡∏™‡∏≤‡∏£)", color=color_label), aspect="auto", color_continuous_scale=colorscale_option, height=graph_height)
                    fig_heatmap.update_layout(xaxis_side="top", xaxis=dict(tickangle=-45), yaxis=dict(tickmode='linear', automargin=True), font=dict(size=10), margin=dict(l=200, r=50, t=100, b=50))
                    st.plotly_chart(fig_heatmap, use_container_width=True)
                    st.caption("üìñ **‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡πà‡∏≤‡∏ô Heatmap:**\n- **‡∏™‡∏µ‡πÄ‡∏Ç‡πâ‡∏° (‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô/‡∏°‡πà‡∏ß‡∏á):** ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£ **‡∏ô‡πâ‡∏≠‡∏¢**\n- **‡∏™‡∏µ‡∏≠‡πà‡∏≠‡∏ô (‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á/‡πÅ‡∏î‡∏á):** ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£ **‡∏°‡∏≤‡∏Å**\n- **‡πÅ‡∏Å‡∏ô X:** ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n- **‡πÅ‡∏Å‡∏ô Y:** ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö")
                    st.markdown("---")
                    st.subheader("üíæ Export Options")
                    exp_col1, exp_col2 = st.columns(2)
                    with exp_col1:
                        html_bytes = fig_heatmap.to_html(include_plotlyjs='cdn').encode()
                        st.download_button("üì• Download Heatmap (HTML)", html_bytes, "heatmap.html", "text/html", use_container_width=True, help="‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå HTML ‡πÅ‡∏ö‡∏ö Interactive (‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢ Browser)")
                    with exp_col2:
                        st.download_button("üì• Download Data (XLSX)", to_excel(heatmap_pivot.reset_index()), "heatmap_data.xlsx", use_container_width=True)
                else:
                    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á")
            except Exception as e:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap: {e}")
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")

    with tabs[1]:
        st.header("üß¨ ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (PCA)")
        st.info("üí° ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô = ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô")
        if len(base_analysis_df['Sample'].unique()) < 2:
            st.warning("‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ PCA")
        else:
            try:
                pca_pivot = base_analysis_df.pivot_table(index='Sample', columns='Compound', values='Area', aggfunc='sum').fillna(0)
                scaler = StandardScaler()
                scaled_data = scaler.fit_transform(pca_pivot)
                pca = PCA(n_components=2)
                principal_components = pca.fit_transform(scaled_data)
                pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'], index=pca_pivot.index)
                explained_var = pca.explained_variance_ratio_
                fig_pca = px.scatter(pca_df, x='PC1', y='PC2', text=pca_df.index, labels={'PC1': f'PC1 ({explained_var[0]*100:.2f}%)', 'PC2': f'PC2 ({explained_var[1]*100:.2f}%)'}, title="2D PCA Clustering of Samples")
                fig_pca.update_traces(textposition='top center', marker=dict(size=15, line=dict(width=2, color='white')))
                fig_pca.update_layout(yaxis=dict(scaleanchor="x", scaleratio=1), xaxis=dict(zeroline=True, zerolinewidth=1, zerolinecolor='lightgray'), yaxis2=dict(zeroline=True, zerolinewidth=1, zerolinecolor='lightgray'), height=600)
                st.plotly_chart(fig_pca, use_container_width=True)
                total_var = (explained_var[0] + explained_var[1]) * 100
                st.caption(f"üìñ **‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡πà‡∏≤‡∏ô PCA Plot:**\n- ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î = 1 ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n- ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô = ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô\n- PC1 ‡πÅ‡∏•‡∏∞ PC2 ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏£‡∏ß‡∏° **{total_var:.2f}%**")
            except Exception as e:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì PCA: {e}")

    with tabs[2]:
        st.header("üëÉ ‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏•‡∏¥‡πà‡∏ô")
        st.info("üí° ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        df_flavor_db = get_flavor_database()
        if not df_flavor_db.empty:
            found_compounds = base_analysis_df[['Compound']].drop_duplicates()
            flavor_profile = pd.merge(found_compounds, df_flavor_db, on='Compound', how='left')
            compounds_with_flavor = flavor_profile.dropna(subset=['Flavor_Descriptor'])
            compounds_without_flavor = flavor_profile[flavor_profile['Flavor_Descriptor'].isna()]
            col_fp1, col_fp2, col_fp3 = st.columns(3)
            col_fp1.metric("üß™ ‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", len(found_compounds))
            col_fp2.metric("‚úÖ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô", len(compounds_with_flavor))
            col_fp3.metric("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", len(compounds_without_flavor))
            if not compounds_with_flavor.empty:
                st.markdown("---")
                st.subheader("üìã ‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô")
                st.dataframe(compounds_with_flavor[['Compound', 'Flavor_Descriptor', 'Source']], use_container_width=True, hide_index=True, column_config={"Compound": "‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£", "Flavor_Descriptor": "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏•‡∏¥‡πà‡∏ô", "Source": "‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"})
                st.markdown("---")
                st.subheader("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                source_counts = compounds_with_flavor['Source'].value_counts().reset_index()
                source_counts.columns = ['‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏£']
                st.dataframe(source_counts, use_container_width=True, hide_index=True)
                st.markdown("---")
                st.download_button("üì• Download Flavor Profile (XLSX)", to_excel(compounds_with_flavor), "flavor_profile.xlsx", help="‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Excel")
            else:
                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÉ‡∏î‡πÜ ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        else:
            st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô‡πÑ‡∏î‡πâ - ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")

    with tabs[3]:
        st.header("üîç ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö")
        st.info("üí° ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å '‡∏Å‡∏•‡∏¥‡πà‡∏ô' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏™‡∏≤‡∏£‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô ‡πÅ‡∏•‡∏∞‡∏û‡∏ö‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà")
        df_flavor_db = get_flavor_database()
        if not df_flavor_db.empty:
            search_flavor = st.text_input("üîç ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:", "", placeholder="‡πÄ‡∏ä‡πà‡∏ô fruity, nutty, caramel, floral, sweet...").strip().lower()
            if search_flavor:
                try:
                    found_compounds = df_flavor_db[df_flavor_db['Flavor_Descriptor'].str.contains(search_flavor, case=False, na=False)].copy()
                    if not found_compounds.empty:
                        st.subheader(f"üìä ‡∏û‡∏ö {len(found_compounds):,} ‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏•‡∏¥‡πà‡∏ô '{search_flavor}'")
                        samples_compounds = base_analysis_df['Compound'].unique()
                        found_compounds['Found_In_Samples'] = found_compounds['Compound'].isin(samples_compounds)
                        num_found_in_samples = found_compounds['Found_In_Samples'].sum()
                        if num_found_in_samples > 0:
                            st.success(f"‚úÖ ‡∏û‡∏ö {num_found_in_samples} ‡∏™‡∏≤‡∏£‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì!")
                        else:
                            st.info("üí° ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏¥‡πà‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì")
                        st.dataframe(found_compounds[['Compound', 'Flavor_Descriptor', 'Source', 'Found_In_Samples']], column_config={"Compound": "‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£", "Flavor_Descriptor": "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏•‡∏¥‡πà‡∏ô", "Source": "‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "Found_In_Samples": st.column_config.CheckboxColumn("‚úì ‡∏û‡∏ö‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á?", help="‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà")}, use_container_width=True, hide_index=True)
                        compounds_to_plot = found_compounds[found_compounds['Found_In_Samples']]['Compound']
                        if not compounds_to_plot.empty:
                            st.markdown("---")
                            st.subheader(f"üìà ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏¥‡πà‡∏ô '{search_flavor}'")
                            plot_data = base_analysis_df[base_analysis_df['Compound'].isin(compounds_to_plot)]
                            if not plot_data.empty:
                                fig_bar = px.bar(plot_data, x="Sample", y="Area", color="Compound", title=f"‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏¥‡πà‡∏ô '{search_flavor}' ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", labels={"Sample": "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", "Area": "Total Area"}, height=500)
                                st.plotly_chart(fig_bar, use_container_width=True)
                    else:
                        st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏≤‡∏£‡πÉ‡∏î‡πÜ ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏•‡∏¥‡πà‡∏ô '{search_flavor}' ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                except Exception as e:
                    st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {e}")
        else:
            st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏¥‡πà‡∏ô‡πÑ‡∏î‡πâ - ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")

    with tabs[4]:
        st.header("üìä ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏Ñ‡∏£‡∏°‡∏≤‡πÇ‡∏ó‡πÅ‡∏Å‡∏£‡∏°")
        y_option = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡πÅ‡∏Å‡∏ô Y:", ("Height", "Area"), key="overlay_y")
        fig_overlay = go.Figure()
        samples = combined_df['Sample'].unique()
        colors = px.colors.qualitative.Plotly
        for idx, sample in enumerate(samples):
            sample_data = combined_df[combined_df['Sample'] == sample]
            
            hovertemplate = (
                f'<b>{sample}</b>  '
                f'RT: %{{x}}  '
                f'{y_option}: %{{y}}<extra></extra>'
            )
            fig_overlay.add_trace(go.Scatter(
                x=sample_data['R.T.'], 
                y=sample_data[y_option],
                mode='lines', 
                name=sample,
                line=dict(color=colors[idx % len(colors)], width=2),
                hovertemplate=hovertemplate
            ))
        
        fig_overlay.update_layout(xaxis_title="Retention Time (‡∏ô‡∏≤‡∏ó‡∏µ)", yaxis_title=y_option, legend_title_text='Samples', hovermode='x unified', height=600)
        st.plotly_chart(fig_overlay, use_container_width=True)
        st.caption("üìñ **‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡πà‡∏≤‡∏ô Chromatogram Overlay:**\n- **‡πÅ‡∏Å‡∏ô X:** Retention Time\n- **‡πÅ‡∏Å‡∏ô Y:** ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≤‡∏£\n- Peak ‡∏ó‡∏µ‡πà RT ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô = ‡∏™‡∏≤‡∏£‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô")

    with tabs[5]:
        st.header("üìÑ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
        st.dataframe(combined_df, use_container_width=True, height=600)
        st.markdown("---")
        st.download_button("üì• Download All Data (XLSX)", to_excel(combined_df), "all_combined_data.xlsx", help="‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Excel")

# ==============================================================================
# Footer
# ==============================================================================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray; font-size: 12px;'>
    <p>GC-MS Data Comparator & Flavor Explorer v2.1</p>
    <p>Powered by Streamlit | Created by Aniwat Kaewkrod</p>
</div>
""", unsafe_allow_html=True)
